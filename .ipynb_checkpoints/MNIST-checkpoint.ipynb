{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 手写数字分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二分类问题只需要确定一个值，多分类问题要确定每一个分支的可能概率，使用交叉熵函数确定误差（二分类中的loss），交叉熵的含义是用于度量两个分布之间的差异性，衡量模型能否识别的难度。\n",
    "交叉熵学习链接，[link](https://blog.csdn.net/rtygbwwwerr/article/details/50778098)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import mnist\n",
    "from torch import nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "train_set=mnist.MNIST('./data',train=True,download=True)\n",
    "test_set=mnist.MNIST('./data',train=False,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=L size=28x28 at 0x7F328DC28AD0>\n"
     ]
    }
   ],
   "source": [
    "a_data,a_label=train_set[0]\n",
    "print(a_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F328DC28AD0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "#转换格式\n",
    "a_data=np.array(a_data,dtype='float32')\n",
    "print(a_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   3.  18.\n",
      "   18.  18. 126. 136. 175.  26. 166. 255. 247. 127.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.  30.  36.  94. 154. 170. 253.\n",
      "  253. 253. 253. 253. 225. 172. 253. 242. 195.  64.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.  49. 238. 253. 253. 253. 253. 253.\n",
      "  253. 253. 253. 251.  93.  82.  82.  56.  39.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.  18. 219. 253. 253. 253. 253. 253.\n",
      "  198. 182. 247. 241.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.  80. 156. 107. 253. 253. 205.\n",
      "   11.   0.  43. 154.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.  14.   1. 154. 253.  90.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 139. 253. 190.\n",
      "    2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  11. 190. 253.\n",
      "   70.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  35. 241.\n",
      "  225. 160. 108.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  81.\n",
      "  240. 253. 253. 119.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   45. 186. 253. 253. 150.  27.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.  16.  93. 252. 253. 187.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0. 249. 253. 249.  64.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   46. 130. 183. 253. 253. 207.   2.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  39. 148.\n",
      "  229. 253. 253. 253. 250. 182.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  24. 114. 221. 253.\n",
      "  253. 253. 253. 201.  78.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.  23.  66. 213. 253. 253. 253.\n",
      "  253. 198.  81.   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.  18. 171. 219. 253. 253. 253. 253. 195.\n",
      "   80.   9.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.  55. 172. 226. 253. 253. 253. 253. 244. 133.  11.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0. 136. 253. 253. 253. 212. 135. 132.  16.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "print(a_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#拉平成一个一维向量作为神经网络输入\n",
    "def data_tf(x):\n",
    "    x=np.array(x,dtype='float32')/255\n",
    "    x=(x-0.5)/0.5\n",
    "    x=x.reshape((-1,))\n",
    "    x=torch.from_numpy(x)\n",
    "    return x\n",
    "\n",
    "train_set=mnist.MNIST('./data',train=True,transform=data_tf,download=True)\n",
    "test_set=mnist.MNIST('./data',train=False,transform=data_tf,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-0.9765\n",
      "-0.8588\n",
      "-0.8588\n",
      "-0.8588\n",
      "-0.0118\n",
      " 0.0667\n",
      " 0.3725\n",
      "-0.7961\n",
      " 0.3020\n",
      " 1.0000\n",
      " 0.9373\n",
      "-0.0039\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-0.7647\n",
      "-0.7176\n",
      "-0.2627\n",
      " 0.2078\n",
      " 0.3333\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.7647\n",
      " 0.3490\n",
      " 0.9843\n",
      " 0.8980\n",
      " 0.5294\n",
      "-0.4980\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-0.6157\n",
      " 0.8667\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9686\n",
      "-0.2706\n",
      "-0.3569\n",
      "-0.3569\n",
      "-0.5608\n",
      "-0.6941\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-0.8588\n",
      " 0.7176\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.5529\n",
      " 0.4275\n",
      " 0.9373\n",
      " 0.8902\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-0.3725\n",
      " 0.2235\n",
      "-0.1608\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.6078\n",
      "-0.9137\n",
      "-1.0000\n",
      "-0.6627\n",
      " 0.2078\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-0.8902\n",
      "-0.9922\n",
      " 0.2078\n",
      " 0.9843\n",
      "-0.2941\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      " 0.0902\n",
      " 0.9843\n",
      " 0.4902\n",
      "-0.9843\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-0.9137\n",
      " 0.4902\n",
      " 0.9843\n",
      "-0.4510\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-0.7255\n",
      " 0.8902\n",
      " 0.7647\n",
      " 0.2549\n",
      "-0.1529\n",
      "-0.9922\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-0.3647\n",
      " 0.8824\n",
      " 0.9843\n",
      " 0.9843\n",
      "-0.0667\n",
      "-0.8039\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-0.6471\n",
      " 0.4588\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.1765\n",
      "-0.7882\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-0.8745\n",
      "-0.2706\n",
      " 0.9765\n",
      " 0.9843\n",
      " 0.4667\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      " 0.9529\n",
      " 0.9843\n",
      " 0.9529\n",
      "-0.4980\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-0.6392\n",
      " 0.0196\n",
      " 0.4353\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.6235\n",
      "-0.9843\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-0.6941\n",
      " 0.1608\n",
      " 0.7961\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9608\n",
      " 0.4275\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-0.8118\n",
      "-0.1059\n",
      " 0.7333\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.5765\n",
      "-0.3882\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-0.8196\n",
      "-0.4824\n",
      " 0.6706\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.5529\n",
      "-0.3647\n",
      "-0.9843\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-0.8588\n",
      " 0.3412\n",
      " 0.7176\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.5294\n",
      "-0.3725\n",
      "-0.9294\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-0.5686\n",
      " 0.3490\n",
      " 0.7725\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9137\n",
      " 0.0431\n",
      "-0.9137\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      " 0.0667\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.9843\n",
      " 0.6627\n",
      " 0.0588\n",
      " 0.0353\n",
      "-0.8745\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "-1.0000\n",
      "[torch.FloatTensor of size 784]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a_data,a_label=train_set[0]\n",
    "print(a_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(a_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用pytorch自带的迭代器，数据量如果太大，无法一次读入内存，使用迭代器一次读入一部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_data=DataLoader(train_set,batch_size=64,shuffle=True)\n",
    "test_data=DataLoader(test_set,batch_size=128,shuffle=False)\n",
    "a,a_label=next(iter(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784])\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print(a_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一次处理64个数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义网络\n",
    "net=nn.Sequential(\n",
    "    nn.Linear(784,400),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(400,200),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200,100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=400, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=400, out_features=200, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()#交叉熵\n",
    "optimizer=torch.optim.SGD(net.parameters(),1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, Train Loss: 0.000046, Train Acc: 1.000000, Eval Loss: 0.083135, Eval Acc: 0.000000\n",
      "epoch: 1, Train Loss: 0.000044, Train Acc: 1.000000, Eval Loss: 0.083507, Eval Acc: 0.000000\n",
      "epoch: 2, Train Loss: 0.000043, Train Acc: 1.000000, Eval Loss: 0.083681, Eval Acc: 0.000000\n",
      "epoch: 3, Train Loss: 0.000042, Train Acc: 1.000000, Eval Loss: 0.083779, Eval Acc: 0.000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d378dc66dceb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ning/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ning/anaconda2/lib/python2.7/site-packages/torchvision-0.1.9-py2.7.egg/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-c5f874f2b4ec>\u001b[0m in \u001b[0;36mdata_tf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdata_tf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 开始训练\n",
    "losses = []\n",
    "acces = []\n",
    "eval_losses = []\n",
    "eval_acces = []\n",
    "\n",
    "for e in range(20):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    net.train()\n",
    "    for im, label in train_data:\n",
    "        im = Variable(im)\n",
    "        label = Variable(label)\n",
    "        # 前向传播\n",
    "        out = net(im)\n",
    "        loss = criterion(out, label)\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 记录误差\n",
    "        train_loss += loss.data[0]\n",
    "        # 计算分类的准确率\n",
    "        _, pred = out.max(1)\n",
    "        num_correct = (pred == label).sum().data[0]\n",
    "        acc = num_correct / im.shape[0]\n",
    "        train_acc += acc\n",
    "        \n",
    "    losses.append(train_loss / len(train_data))\n",
    "    acces.append(train_acc / len(train_data))\n",
    "    # 在测试集上检验效果\n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    net.eval() # 将模型改为预测模式\n",
    "    for im, label in test_data:\n",
    "        im = Variable(im)\n",
    "        label = Variable(label)\n",
    "        out = net(im)\n",
    "        loss = criterion(out, label)\n",
    "        # 记录误差\n",
    "        eval_loss += loss.data[0]\n",
    "        # 记录准确率\n",
    "        _, pred = out.max(1)\n",
    "        num_correct = (pred == label).sum().data[0]\n",
    "        acc = num_correct / im.shape[0]\n",
    "        eval_acc += acc\n",
    "    eval_losses.append(eval_loss / len(test_data))\n",
    "    eval_acces.append(eval_acc / len(test_data))\n",
    "    print('epoch: {}, Train Loss: {:.6f}, Train Acc: {:.6f}, Eval Loss: {:.6f}, Eval Acc: {:.6f}'\n",
    "          .format(e, train_loss / len(train_data), train_acc / len(train_data), \n",
    "                     eval_loss / len(test_data), eval_acc / len(test_data)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一跑这个程序，电脑风扇就呼呼的.搞不懂为什么输出的train_acc和test_acc会这么诡异。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
